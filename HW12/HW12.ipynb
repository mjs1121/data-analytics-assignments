{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef518c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv_annotate10_7_1.txt   arxiv_annotate10_7_2.txt   arxiv_annotate10_7_3.txt   arxiv_annotate1_13_1.txt   arxiv_annotate1_13_2.txt   arxiv_annotate1_13_3.txt   arxiv_annotate2_66_1.txt   arxiv_annotate2_66_2.txt   arxiv_annotate2_66_3.txt   arxiv_annotate3_80_1.txt   arxiv_annotate3_80_2.txt   arxiv_annotate3_80_3.txt   arxiv_annotate4_168_1.txt   arxiv_annotate4_168_2.txt   arxiv_annotate4_168_3.txt   arxiv_annotate5_240_1.txt   arxiv_annotate5_240_2.txt   arxiv_annotate5_240_3.txt   arxiv_annotate6_52_1.txt   arxiv_annotate6_52_2.txt   arxiv_annotate6_52_3.txt   arxiv_annotate7_268_1.txt   arxiv_annotate7_268_2.txt   arxiv_annotate7_268_3.txt   arxiv_annotate8_81_1.txt   arxiv_annotate8_81_2.txt   arxiv_annotate8_81_3.txt   arxiv_annotate9_279_1.txt   arxiv_annotate9_279_2.txt   arxiv_annotate9_279_3.txt   jdm_annotate10_210_1.txt   jdm_annotate10_210_2.txt   jdm_annotate10_210_3.txt   jdm_annotate1_103_1.txt   jdm_annotate1_103_2.txt   jdm_annotate1_103_3.txt   jdm_annotate2_107_1.txt   jdm_annotate2_107_2.txt   jdm_annotate2_107_3.txt   jdm_ann^otate3_120_1.txt   jdm_annotate3_120_2.txt   jdm_annotate3_120_3.txt   jdm_annotate4_220_1.txt   jdm_annotate4_220_2.txt   jdm_annotate4_220_3.txt   jdm_annotate5_228_1.txt   jdm_annotate5_228_2.txt   jdm_annotate5_228_3.txt   jdm_annotate6_32_1.txt   jdm_anno&tate6_32_2.txt   jdm_annotate6_32_3.txt   jdm_annotate7_265_1.txt   jdm_annotate7_265_2.txt   jdm_annotate7_265_3.txt   jdm_annotate8_177_1.txt   jdm_annotat#e8_177_2.txt   jdm_annotate8_177_3.txt   jdm_annotate9_45_1.txt   jdm_annotate9_45_2.txt   jdm_annotate9_45_3.txt   plos_annotate10_1140_1.txt   plos_annotate10_1140_2.txt   plos_annotate10_1140_3.txt   plos_annotate1_6_1.txt   plos_annotat*e1_6_2.txt   plos_annotate1_6_3.txt   plos_annotate2_336_1.txt   plos_annotate2_336_2.txt   plos_annotate2_336_3.txt   plos_annotate3_798_1.txt   plos_annotate3_798_2.txt   plos_annotate3_798_3.txt   plos_annotate4_1052_1.txt   plos_annotate4_1052_2.txt   plos_annotate4_1052_3.txt   plos_annotate5_1375_1.txt   plos_annotate5_1375_2.txt   plos_anno%tate5_1375_3.txt   plos_annotate6_1032_1.txt   plos_annotate6_1032_2.txt   plos_annotate6_1032_3.txt   plos_annotate7_1233_1.txt   plos_annot@ate7_1233_2.txt   plos_annotate7_1233_3.txt   plos_annotate8_123_1.txt   plos_annotate8_123_2.txt   plos_annotate8_123_3.txt   plos_annotate9_1187_1.txt   plos_annotate9_1187_2.txt   plos_annotate9_1187_3.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Question 1 - How many File Names in Provided File?\n",
    "file = open('Assignment_12.txt', 'r')\n",
    "text1 = file.read()\n",
    "file.close()\n",
    "\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4efbd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since all the names are filenames, we can technically \n",
    "# seperate each entry into an array of words\n",
    "regex1 = re.compile('\\s+')\n",
    "text1_words = regex1.split(text1)\n",
    "\n",
    "# However, we are not really checking for files, so a\n",
    "# more robust way is to just create a pattern that looks\n",
    "# for '.' followed by text, since all filename extensions\n",
    "# much match that form\n",
    "regex2 = re.compile('.[A-Z0-9]+\\s+', flags=re.IGNORECASE)\n",
    "text1_files = regex2.split(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "baee079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on Spaces Method:    90\n",
      "Split on File Extensions:  90\n"
     ]
    }
   ],
   "source": [
    "# Question 1 Results\n",
    "print('Split on Spaces Method:   ', len(text1_words))\n",
    "print('Split on File Extensions: ', len(text1_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "22703ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filename matches to pattern:  84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['arxiv_annotate10_7_1.txt',\n",
       " 'arxiv_annotate10_7_2.txt',\n",
       " 'arxiv_annotate10_7_3.txt',\n",
       " 'arxiv_annotate1_13_1.txt',\n",
       " 'arxiv_annotate1_13_2.txt',\n",
       " 'arxiv_annotate1_13_3.txt',\n",
       " 'arxiv_annotate2_66_1.txt',\n",
       " 'arxiv_annotate2_66_2.txt',\n",
       " 'arxiv_annotate2_66_3.txt',\n",
       " 'arxiv_annotate3_80_1.txt',\n",
       " 'arxiv_annotate3_80_2.txt',\n",
       " 'arxiv_annotate3_80_3.txt',\n",
       " 'arxiv_annotate4_168_1.txt',\n",
       " 'arxiv_annotate4_168_2.txt',\n",
       " 'arxiv_annotate4_168_3.txt',\n",
       " 'arxiv_annotate5_240_1.txt',\n",
       " 'arxiv_annotate5_240_2.txt',\n",
       " 'arxiv_annotate5_240_3.txt',\n",
       " 'arxiv_annotate6_52_1.txt',\n",
       " 'arxiv_annotate6_52_2.txt',\n",
       " 'arxiv_annotate6_52_3.txt',\n",
       " 'arxiv_annotate7_268_1.txt',\n",
       " 'arxiv_annotate7_268_2.txt',\n",
       " 'arxiv_annotate7_268_3.txt',\n",
       " 'arxiv_annotate8_81_1.txt',\n",
       " 'arxiv_annotate8_81_2.txt',\n",
       " 'arxiv_annotate8_81_3.txt',\n",
       " 'arxiv_annotate9_279_1.txt',\n",
       " 'arxiv_annotate9_279_2.txt',\n",
       " 'arxiv_annotate9_279_3.txt',\n",
       " 'jdm_annotate10_210_1.txt',\n",
       " 'jdm_annotate10_210_2.txt',\n",
       " 'jdm_annotate10_210_3.txt',\n",
       " 'jdm_annotate1_103_1.txt',\n",
       " 'jdm_annotate1_103_2.txt',\n",
       " 'jdm_annotate1_103_3.txt',\n",
       " 'jdm_annotate2_107_1.txt',\n",
       " 'jdm_annotate2_107_2.txt',\n",
       " 'jdm_annotate2_107_3.txt',\n",
       " 'jdm_annotate3_120_2.txt',\n",
       " 'jdm_annotate3_120_3.txt',\n",
       " 'jdm_annotate4_220_1.txt',\n",
       " 'jdm_annotate4_220_2.txt',\n",
       " 'jdm_annotate4_220_3.txt',\n",
       " 'jdm_annotate5_228_1.txt',\n",
       " 'jdm_annotate5_228_2.txt',\n",
       " 'jdm_annotate5_228_3.txt',\n",
       " 'jdm_annotate6_32_1.txt',\n",
       " 'jdm_annotate6_32_3.txt',\n",
       " 'jdm_annotate7_265_1.txt',\n",
       " 'jdm_annotate7_265_2.txt',\n",
       " 'jdm_annotate7_265_3.txt',\n",
       " 'jdm_annotate8_177_1.txt',\n",
       " 'jdm_annotate8_177_3.txt',\n",
       " 'jdm_annotate9_45_1.txt',\n",
       " 'jdm_annotate9_45_2.txt',\n",
       " 'jdm_annotate9_45_3.txt',\n",
       " 'plos_annotate10_1140_1.txt',\n",
       " 'plos_annotate10_1140_2.txt',\n",
       " 'plos_annotate10_1140_3.txt',\n",
       " 'plos_annotate1_6_1.txt',\n",
       " 'plos_annotate1_6_3.txt',\n",
       " 'plos_annotate2_336_1.txt',\n",
       " 'plos_annotate2_336_2.txt',\n",
       " 'plos_annotate2_336_3.txt',\n",
       " 'plos_annotate3_798_1.txt',\n",
       " 'plos_annotate3_798_2.txt',\n",
       " 'plos_annotate3_798_3.txt',\n",
       " 'plos_annotate4_1052_1.txt',\n",
       " 'plos_annotate4_1052_2.txt',\n",
       " 'plos_annotate4_1052_3.txt',\n",
       " 'plos_annotate5_1375_1.txt',\n",
       " 'plos_annotate5_1375_2.txt',\n",
       " 'plos_annotate6_1032_1.txt',\n",
       " 'plos_annotate6_1032_2.txt',\n",
       " 'plos_annotate6_1032_3.txt',\n",
       " 'plos_annotate7_1233_1.txt',\n",
       " 'plos_annotate7_1233_3.txt',\n",
       " 'plos_annotate8_123_1.txt',\n",
       " 'plos_annotate8_123_2.txt',\n",
       " 'plos_annotate8_123_3.txt',\n",
       " 'plos_annotate9_1187_1.txt',\n",
       " 'plos_annotate9_1187_2.txt',\n",
       " 'plos_annotate9_1187_3.txt']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 2 - Identify Pattern of filenames and Count total\n",
    "# My assumption on this is that each filename is supposed to\n",
    "# follow something like this:\n",
    "# a-z(2-5? times)_annotate_0-9(1-2?)_0-9(1-4?)_0-9(1).txt\n",
    "\n",
    "# We can assume the ranges are loose, and may utilize 0-9+\n",
    "\n",
    "file_pattern = r'[a-z]+_annotate[0-9]+_[0-9]+_[0-9].txt'\n",
    "regex3 = re.compile(file_pattern, flags=re.IGNORECASE)\n",
    "\n",
    "text1_matches = regex3.findall(text1)\n",
    "print('\\nFilename matches to pattern: ', len(text1_matches))\n",
    "display(text1_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "56464b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not matching file names:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['   jdm_ann^otate3_120_1.txt   ',\n",
       " '   jdm_anno&tate6_32_2.txt   ',\n",
       " '   jdm_annotat#e8_177_2.txt   ',\n",
       " '   plos_annotat*e1_6_2.txt   ',\n",
       " '   plos_anno%tate5_1375_3.txt   ',\n",
       " '   plos_annot@ate7_1233_2.txt   ']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 3 - Get File Names where Pattern wasn't Matched\n",
    "# First, let is split the text file based on regex from\n",
    "# last question, this will return empty spaces as well\n",
    "# as the non-matching names\n",
    "names_unmatched = regex3.split(text1)\n",
    "\n",
    "unmatched_files = []\n",
    "\n",
    "# Now we can filter out the space entries only through a for loop\n",
    "txt_ext = r'.txt\\s+'\n",
    "regex5 = re.compile(txt_ext)\n",
    "for i in range(len(names_unmatched)):\n",
    "    if regex5.search(names_unmatched[i]):\n",
    "#        print(names_unmatched[i])\n",
    "        unmatched_files.append(names_unmatched[i])\n",
    "        \n",
    "print('Not matching file names:')\n",
    "display(unmatched_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0018979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#',\n",
       " '#',\n",
       " '#',\n",
       " 'abstract',\n",
       " '#',\n",
       " '#',\n",
       " '#',\n",
       " 'MISC',\n",
       " 'although',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'as',\n",
       " 'level',\n",
       " 'topology',\n",
       " 'has',\n",
       " 'been',\n",
       " 'extensively',\n",
       " 'studied',\n",
       " 'over',\n",
       " 'the',\n",
       " 'past',\n",
       " 'few',\n",
       " 'years',\n",
       " 'little',\n",
       " 'is']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 4 - Normalize the new file and determine counts\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "\n",
    "# First we import the file and read\n",
    "file2 = open('arxiv_annotate1_13_1.txt', 'r')\n",
    "text2 = file2.read()\n",
    "file2.close()\n",
    "\n",
    "# Now we can use nltk to turn the text into words\n",
    "text2_words = nltk.word_tokenize(text2)\n",
    "text2_words[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad85d895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words found:  334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 44, 'of': 34, 'as': 28, 'and': 24, 'MISC': 20, 'we': 20, 'a': 19, 'in': 19, 'to': 18, 'internet': 15, ...})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now, we can utilize FreqDist to turn the \n",
    "# words into a dictionary of unique words and\n",
    "# respective counts\n",
    "dist = nltk.FreqDist(text2_words)\n",
    "\n",
    "print('Unique words found: ', len(dist))\n",
    "# We can view the Head just by displaying the dictionary\n",
    "display(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2d299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
